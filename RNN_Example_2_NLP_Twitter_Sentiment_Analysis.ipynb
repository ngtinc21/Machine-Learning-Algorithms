{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Example 2 - NLP_Twitter Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Pr2sA_WKRbIv",
        "g4T69CifZoo3",
        "LSIuZ9bsxFhg"
      ],
      "authorship_tag": "ABX9TyNVzKIEANEM9yDHvWfEDLir",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngtinc21/Machine-Learning-Algorithms/blob/main/RNN_Example_2_NLP_Twitter_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP Twitter Sentiment Analysis - Positive/Negative Sentiment**\n",
        "\n",
        "The example is to analyze the nature of Tweets using NLP. The word limit of a single tweet has 140 characters. Since the analysis is a supervised learning task, the training dataset which consists of Tweets labeled with “1” or “0” and a test dataset without labels.\n",
        "\n",
        "The training data consists of Tweets labeled with \"1\" or \"0\".\n",
        "\n",
        "Label “0”: Positive Sentiment\n",
        "Label “1”: Negative Sentiment\n",
        "\n",
        "  * `train_tweets.csv` contains Training dataset which consists of Tweets labeled “1” or “0”\n",
        "  * `test_tweets.csv` contains Test dataset without labels.\n"
      ],
      "metadata": {
        "id": "bmDgt6ZBd8He"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM14uElY8_9E"
      },
      "source": [
        "## **1. Data Acquisition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTkie2OpAStx"
      },
      "source": [
        "**Importing required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7P1b3KhrrN3"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OExN-4P9KaO"
      },
      "source": [
        "### **Downloading Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWClOleMlyA7",
        "outputId": "b4279bc9-ec0d-44c5-e3c2-8aa552eb1f3e"
      },
      "source": [
        "! git clone https://github.com/MohamedAfham/Twitter-Sentiment-Analysis-Supervised-Learning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Twitter-Sentiment-Analysis-Supervised-Learning' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZeO-gvdqS74"
      },
      "source": [
        "### **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAvxTEVXsT16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "06c9207f-2319-45dd-ca77-41e4129107af"
      },
      "source": [
        "train_tweets= pd.read_csv(\"/content/Twitter-Sentiment-Analysis-Supervised-Learning/Data/train_tweets.csv\")\n",
        "train_tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-73380318-d407-4976-852f-b66ac8a06d8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>31958</td>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>31959</td>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>31960</td>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>31961</td>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>31962</td>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73380318-d407-4976-852f-b66ac8a06d8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73380318-d407-4976-852f-b66ac8a06d8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73380318-d407-4976-852f-b66ac8a06d8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          id  label                                              tweet\n",
              "0          1      0   @user when a father is dysfunctional and is s...\n",
              "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2          3      0                                bihday your majesty\n",
              "3          4      0  #model   i love u take with u all the time in ...\n",
              "4          5      0             factsguide: society now    #motivation\n",
              "...      ...    ...                                                ...\n",
              "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
              "31958  31959      0    to see nina turner on the airwaves trying to...\n",
              "31959  31960      0  listening to sad songs on a monday morning otw...\n",
              "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
              "31961  31962      0                   thank you @user for you follow  \n",
              "\n",
              "[31962 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylPjtURqs-72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "da217b62-7688-4999-8447-c4cc54d12466"
      },
      "source": [
        "test_tweets = pd.read_csv('/content/Twitter-Sentiment-Analysis-Supervised-Learning/Data/test_tweets.csv')\n",
        "test_tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-39115e82-7e6c-42e5-8dde-c242c1764e75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17192</th>\n",
              "      <td>49155</td>\n",
              "      <td>thought factory: left-right polarisation! #tru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17193</th>\n",
              "      <td>49156</td>\n",
              "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17194</th>\n",
              "      <td>49157</td>\n",
              "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17195</th>\n",
              "      <td>49158</td>\n",
              "      <td>happy, at work conference: right mindset leads...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17196</th>\n",
              "      <td>49159</td>\n",
              "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17197 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39115e82-7e6c-42e5-8dde-c242c1764e75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39115e82-7e6c-42e5-8dde-c242c1764e75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39115e82-7e6c-42e5-8dde-c242c1764e75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          id                                              tweet\n",
              "0      31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1      31964   @user #white #supremacists want everyone to s...\n",
              "2      31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              "3      31966  is the hp and the cursed child book up for res...\n",
              "4      31967    3rd #bihday to my amazing, hilarious #nephew...\n",
              "...      ...                                                ...\n",
              "17192  49155  thought factory: left-right polarisation! #tru...\n",
              "17193  49156  feeling like a mermaid ð #hairflip #neverre...\n",
              "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...\n",
              "17195  49158  happy, at work conference: right mindset leads...\n",
              "17196  49159  my   song \"so glad\" free download!  #shoegaze ...\n",
              "\n",
              "[17197 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRGExFSGtWPp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "0f00f14f-5811-4c81-c4b4-eb15f7797b50"
      },
      "source": [
        "# Removing the \"id\" column from the train data. The dataframe will now have only 2 columns: `label` and `tweet`.\n",
        "train_tweets= train_tweets[[\"label\",\"tweet\"]]\n",
        "train_tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-49e3dc4d-e85d-4052-98f5-6b080d333bfc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49e3dc4d-e85d-4052-98f5-6b080d333bfc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49e3dc4d-e85d-4052-98f5-6b080d333bfc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49e3dc4d-e85d-4052-98f5-6b080d333bfc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       label                                              tweet\n",
              "0          0   @user when a father is dysfunctional and is s...\n",
              "1          0  @user @user thanks for #lyft credit i can't us...\n",
              "2          0                                bihday your majesty\n",
              "3          0  #model   i love u take with u all the time in ...\n",
              "4          0             factsguide: society now    #motivation\n",
              "...      ...                                                ...\n",
              "31957      0  ate @user isz that youuu?ðððððð...\n",
              "31958      0    to see nina turner on the airwaves trying to...\n",
              "31959      0  listening to sad songs on a monday morning otw...\n",
              "31960      1  @user #sikh #temple vandalised in in #calgary,...\n",
              "31961      0                   thank you @user for you follow  \n",
              "\n",
              "[31962 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IatkMtt5tryf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037f6dd4-5f3f-4bee-c5d7-54b0cef87b73"
      },
      "source": [
        "# Removing the \"id\" column from the test data. The dataframe now has only 1 column: `tweet`.\n",
        "test = test_tweets[\"tweet\"]\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        #studiolife #aislife #requires #passion #dedic...\n",
              "1         @user #white #supremacists want everyone to s...\n",
              "2        safe ways to heal your #acne!!    #altwaystohe...\n",
              "3        is the hp and the cursed child book up for res...\n",
              "4          3rd #bihday to my amazing, hilarious #nephew...\n",
              "                               ...                        \n",
              "17192    thought factory: left-right polarisation! #tru...\n",
              "17193    feeling like a mermaid ð #hairflip #neverre...\n",
              "17194    #hillary #campaigned today in #ohio((omg)) &am...\n",
              "17195    happy, at work conference: right mindset leads...\n",
              "17196    my   song \"so glad\" free download!  #shoegaze ...\n",
              "Name: tweet, Length: 17197, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv3VfNpKCl7r"
      },
      "source": [
        "## **2. Exploratory Data Analysis**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bCGyrsGHov4"
      },
      "source": [
        "### **1) Tweet Length**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q54YgUepGagd"
      },
      "source": [
        "# looking at the length of each Tweet\n",
        "train_tweets['length'] = train_tweets['tweet'].apply(len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBL634u8uRFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df17955c-6a66-4b92-a8ed-f318527efcbd"
      },
      "source": [
        "# Visualizing the average length of Tweets with Positive Sentiment (label \"0\") compare to that of Tweets with Negative Sentiment (label \"1\").\n",
        "# From the sns plot below, the average word length of tweets in each category is almost the same.\n",
        "sns.barplot('label','length',data = train_tweets)\n",
        "plt.title('Average Word Length vs Label')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhfQ3oyWLFht"
      },
      "source": [
        "### **2) Data Label Distribution**\n",
        "A balanced dataset is the one that contains equal or almost equal number of samples from the positive and negative class.  The number of Tweets with Positive Sentiment (label \"0\") and the number of Tweets with Negative Sentiment (label \"1\") are to be examined below.\n",
        "\n",
        "From the graph below, there is a major imbalance in the data. There are a lot more tweets labelled \"0\" and a very few ones labelled \"1\". \n",
        "\n",
        "**Imbalanced Data**\n",
        "\n",
        "Imbalanced classes are a common problem in machine learning classification where there are a disproportionate ratio of observations in each class. Class imbalance can be found in many different areas including medical diagnosis, spam filtering, and fraud detection. More references are in [this article](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPVWzjBZuYa0"
      },
      "source": [
        "# Plotting the number of Tweets with Positive Sentiment (label \"0\") and the number of Tweets with Negative Sentiment (label \"1\") in the dataset.\n",
        "sns.countplot(x= 'label',data = train_tweets)\n",
        "plt.title('Label Counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_LeEDSbUCMR"
      },
      "source": [
        "### **3. Text Processing**\n",
        "\n",
        "The main issue with this data is that it is all in text format (strings). The classification algorithms need some sort of numerical feature vector to perform the classification task. In this lesson, tried out the following techniques of preprocessing the raw data:\n",
        "1. Removal of punctuations.\n",
        "2. Removal of commonly used words (stopwords).\n",
        "3. Normalization of words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the`nltk` library for text processing\n",
        "import nltk"
      ],
      "metadata": {
        "id": "d-rl08N0ZTO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr2sA_WKRbIv"
      },
      "source": [
        "#### **i) Removal Of Punctuations**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2x5FHrcJSyJ"
      },
      "source": [
        "# import `TextBlob` library to remove all the punctuations from the Tweet\n",
        "nltk.download('punkt')\n",
        "from textblob import TextBlob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFi4AftGYVV9"
      },
      "source": [
        "# Generating the list of words in the tweet (with hastags and other punctuations removed)\n",
        "def form_sentence(tweet):\n",
        "  # TextBlob(tweet) creates an instance of tweet which can be processed by the Library.\n",
        "  tweet_blob = TextBlob(tweet)\n",
        "  # returns a string by joining all the elements of the list, separated by a string separator, which is a space (`\" \"`) in this case.\n",
        "  return ' '.join(tweet_blob.words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it3fgQfzF715"
      },
      "source": [
        "# example\n",
        "form_sentence(\"#this is an good and clear example!!! XDD :)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4T69CifZoo3"
      },
      "source": [
        "#### **ii) Removal Of Stopwords And Words With Unusual Symbols** \n",
        "\n",
        "Stopwords are very common words in english, for example 'the', 'a', etc. \n",
        "- Import a list of stopwords from the NLTK library to remove them. \n",
        "- Stopwords do not make sense in learning because they don’t have connections with sentiments. \n",
        "- **Removing them saves the computational power** as well as **increases the accuracy of the model**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79rSvTZlEtBC"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TBp5S9CZptw"
      },
      "source": [
        "# Removing stopwords and words with unusual symbols\n",
        "def no_user_alpha(tweet):\n",
        "    # removes the keyword \"user\" from the tweet\n",
        "    tweet_list = [ele for ele in tweet.split() if ele != 'user']\n",
        "\n",
        "    # removes any non-word character(s) (e.g \"#\", \"@\") or number(s) at the start of a word with the use of regular expression. For example \"@Hello, \"#Hello\", and \"123Hello\" becomes \"Hello\".\n",
        "    # [Regular Expression](https://www.w3schools.com/python/python_regex.asp)\n",
        "    clean_tokens = [t for t in tweet_list if re.match(r'[^\\W\\d]*$', t)]\n",
        "    clean_s = ' '.join(clean_tokens)\n",
        "\n",
        "    # removes all the stopwords provided by the NTLK Library\n",
        "    clean_mess = [word for word in clean_s.split() if word.lower() not in stopwords.words('english')]\n",
        "    return clean_mess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJkqgc1CF-Ma"
      },
      "source": [
        "# example\n",
        "no_user_alpha(\"#this is a good and clear example!!! :)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw-GWKF8QmJ8"
      },
      "source": [
        "#### **iii) Function For Text Processing (Combining Step i and ii)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyRdP9VHueRu"
      },
      "source": [
        "# Define a single function that will do all 2 steps of text processing:\n",
        "def text_processing(tweet):\n",
        "    \n",
        "    #Generating the list of words in the tweet (hastags and other punctuations removed)\n",
        "    def form_sentence(tweet):\n",
        "        tweet_blob = TextBlob(tweet)\n",
        "        return ' '.join(tweet_blob.words)\n",
        "    new_tweet = form_sentence(tweet)\n",
        "    \n",
        "    #Removing stopwords and words with unusual symbols\n",
        "    def no_user_alpha(tweet):\n",
        "        tweet_list = [ele for ele in tweet.split() if ele != 'user']\n",
        "        clean_tokens = [t for t in tweet_list if re.match(r'[^\\W\\d]*$', t)]\n",
        "        clean_s = ' '.join(clean_tokens)\n",
        "        clean_mess = [word for word in clean_s.split() if word.lower() not in stopwords.words('english')]\n",
        "        return clean_mess\n",
        "    no_punc_tweet = no_user_alpha(new_tweet)\n",
        "    \n",
        "    return no_punc_tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfS4yD1munBi"
      },
      "source": [
        "# apply the text processing function to our train and test dataframes\n",
        "# apply() method to apply a function to entire column in the dataframe\n",
        "train_tweets['tweet_list'] = train_tweets['tweet'].apply(text_processing)\n",
        "test_tweets['tweet_list'] = test_tweets['tweet'].apply(text_processing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-n2nvBi4Z8-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "3b2da48c-9b69-4661-e707-aba86654e8c7"
      },
      "source": [
        "# comparing the original list and the list with only important words in the same dataframe\n",
        "train_tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ea9b8ce7-0d4a-4fd3-8aea-a66062a80382\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>length</th>\n",
              "      <th>tweet_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>102</td>\n",
              "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>122</td>\n",
              "      <td>[thanks, lyft, credit, ca, use, cause, offer, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>21</td>\n",
              "      <td>[bihday, majesty]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>86</td>\n",
              "      <td>[model, love, u, take, u, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>39</td>\n",
              "      <td>[factsguide, society, motivation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31957</th>\n",
              "      <td>0</td>\n",
              "      <td>ate @user isz that youuu?ðððððð...</td>\n",
              "      <td>68</td>\n",
              "      <td>[ate, isz, youuu]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>0</td>\n",
              "      <td>to see nina turner on the airwaves trying to...</td>\n",
              "      <td>131</td>\n",
              "      <td>[see, nina, turner, airwaves, trying, wrap, ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31959</th>\n",
              "      <td>0</td>\n",
              "      <td>listening to sad songs on a monday morning otw...</td>\n",
              "      <td>63</td>\n",
              "      <td>[listening, sad, songs, monday, morning, otw, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31960</th>\n",
              "      <td>1</td>\n",
              "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
              "      <td>67</td>\n",
              "      <td>[sikh, temple, vandalised, calgary, wso, conde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31961</th>\n",
              "      <td>0</td>\n",
              "      <td>thank you @user for you follow</td>\n",
              "      <td>32</td>\n",
              "      <td>[thank, follow]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31962 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea9b8ce7-0d4a-4fd3-8aea-a66062a80382')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea9b8ce7-0d4a-4fd3-8aea-a66062a80382 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea9b8ce7-0d4a-4fd3-8aea-a66062a80382');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       label  ...                                         tweet_list\n",
              "0          0  ...  [father, dysfunctional, selfish, drags, kids, ...\n",
              "1          0  ...  [thanks, lyft, credit, ca, use, cause, offer, ...\n",
              "2          0  ...                                  [bihday, majesty]\n",
              "3          0  ...                    [model, love, u, take, u, time]\n",
              "4          0  ...                  [factsguide, society, motivation]\n",
              "...      ...  ...                                                ...\n",
              "31957      0  ...                                  [ate, isz, youuu]\n",
              "31958      0  ...  [see, nina, turner, airwaves, trying, wrap, ma...\n",
              "31959      0  ...  [listening, sad, songs, monday, morning, otw, ...\n",
              "31960      1  ...  [sikh, temple, vandalised, calgary, wso, conde...\n",
              "31961      0  ...                                    [thank, follow]\n",
              "\n",
              "[31962 rows x 4 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNQuE-9fVYMc"
      },
      "source": [
        "### **4. Model Building & Training**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# The test dataset 'msg_tset and label_test' here is not from `test_tweets` dataframe\n",
        "msg_train, msg_test, label_train, label_test = train_test_split(train_tweets['tweet'], train_tweets['label'], test_size=0.2)\n"
      ],
      "metadata": {
        "id": "kCw29HWthvJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1 SciKit Learn Pipline (and Naive Bayes Classification) method**"
      ],
      "metadata": {
        "id": "LSIuZ9bsxFhg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8l561b-2_tf"
      },
      "source": [
        "#### **Creating and Training the Model**\n",
        "\n",
        "Pipeline concatenates the output of transformers into a composite feature space. SciKit Learn's [pipeline](http://scikit-learn.org/stable/modules/pipeline.html) is capabled to create a pipeline of workflow. This will allow to set up all the transformations to be done to the data for future use. \n",
        "\n",
        "Library: **sklearn.pipeline.Pipeline**\n",
        "\n",
        "*   Pipeline of transforms with a final estimator.\n",
        "*   The purpose of the pipeline is to assemble several steps that can be **cross-validated** together while setting different parameters. \n",
        "\n",
        "---\n",
        "\n",
        "Sequentially transform and classify the data in the following order:\n",
        "1. **Bag of Words (BOW) Transformation:** A reduced and simplified representation of a text document from selected parts of the text, based on specific criteria, such as word frequency.\n",
        "  * Library: *sklearn.feature_extraction.text.CountVectorizer**\n",
        "    *   Converts a collection of text documents to a matrix of token counts\n",
        "\n",
        "2. **TF-IDF Transformation:** A formula that aims to define the importance of a keyword or phrase within a document or a web page.\n",
        "  * Library: **sklearn.feature_extraction.text.TfidfTransformer**\n",
        "    *   Transforms a count matrix to a normalized tf or tf-idf representation\n",
        "\n",
        "3. **Naive Bayes Classification:** A classification algorithm that uses Bayes' theorem to classify objects. \n",
        "  * Library: **sklearn.naive_bayes.MultinomialNB**\n",
        "    *   Naive Bayes classifier for multinomial models\n",
        "    *   The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaatXc7pIiZg"
      },
      "source": [
        "# Import required libraries\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50BdkJAgx883"
      },
      "source": [
        "# Instantiation\n",
        "pipeline = Pipeline([\n",
        "    ('bow',CountVectorizer(analyzer=text_processing)),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Need an embedding layer to create the first hidden layer\n",
        "msg_train.shape, msg_test.shape, label_train.shape, label_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mROku_DW3Vx-",
        "outputId": "105e4ce4-4db5-4a20-d8da-8b999167a769"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((25569,), (6393,), (25569,), (6393,))"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opgVFsOj_FE4"
      },
      "source": [
        "**iii) Model Fitting**\n",
        "\n",
        "Now we use `.fit` to train the model using the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4FqLIHV-39O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50deb7ce-2512-4488-ddfe-183d894c8e6d"
      },
      "source": [
        "pipeline.fit(msg_train,label_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('bow',\n",
              "                 CountVectorizer(analyzer=<function text_processing at 0x7f8e2aa7fdd0>)),\n",
              "                ('tfidf', TfidfTransformer()),\n",
              "                ('classifier', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQyKIuV8LdPo"
      },
      "source": [
        "### **5. Model Prediction & Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruo9VYTjLgra"
      },
      "source": [
        "#### **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP6NLkJW5iTX"
      },
      "source": [
        "# The predictions is a list of labels (either 0 or 1) for Tweets in test dataset, msg_test\n",
        "predictions = pipeline.predict(msg_test)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxnrdL5n_fiu"
      },
      "source": [
        "Let's see how our predictions looks like. The `predictions` is a list of labels (either 0 or 1) for Tweets in test dataset, `msg_test`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkolimar52Us"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRFO0FbqAJdP"
      },
      "source": [
        "#### **Evaluation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHSwqvRIIsar"
      },
      "source": [
        "# import libraries to evaluate our model to see how good it is in predicting the type of Tweet by comparing the predicted labels with the actual labels in the test dataset.\n",
        "from sklearn.metrics import confusion_matrix, classification_report ,accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQbAcVHnyAsq"
      },
      "source": [
        "# print the Classification Report\n",
        "# use different statistical evaluation methods to evaluate our model. Read more about these methods here\n",
        "# [here](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)\n",
        "print(classification_report(predictions,label_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7plHRXGE56Hk"
      },
      "source": [
        "# Print the accuracy score\n",
        "# Accuracy score is the percentage of correctly predicted labels. Note that there are chances to improve this accuracy by tuning parameters using GridSearchCV and other preprocessing techniques.\n",
        "print(accuracy_score(predictions,label_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3og8X54GlwI"
      },
      "source": [
        "#### **Confusion Matrix**\n",
        "The following confusion matrix can be read as:\n",
        "* Tweets with Positive Sentiment predicted correctly: 5954\n",
        "* Tweets with Positive Sentiment predicted incorrectly: 390\n",
        "* Tweets with Negative Sentiment predicted incorrectly: 2\n",
        "* Tweets with Negative Sentiment predicted correctly: 72"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdIBbsKA58ra"
      },
      "source": [
        "print(confusion_matrix(predictions,label_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.2 LSTM Method**"
      ],
      "metadata": {
        "id": "-WYTO90wYkv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "msg_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXtTRiZxh7E5",
        "outputId": "8ec6baa4-3370-423c-96c4-95d1050b554c"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29452                                   @user   bihday rg \n",
              "7242     new zelda got me, link inventory the world, fr...\n",
              "13905                 5 proven #habits that   people have \n",
              "21143    love you...!!! ððð #friend #friends #...\n",
              "3869     a sad couple days in #orlando . gun violence i...\n",
              "                               ...                        \n",
              "21709    \"stood up for coffee\" uploaded to @user  #brun...\n",
              "10495    defo missing mummy karen @user #misogs   #zshq...\n",
              "24377                     about to see @user in conce!!!  \n",
              "7892      @user when you get excited about summer but t...\n",
              "31700     @user camp colca, camp titicaca and camp mora...\n",
              "Name: tweet, Length: 6393, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2vec\n",
        "import gensim\n",
        "\n",
        "# WORD2VEC \n",
        "W2V_SIZE = 300\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 32\n",
        "W2V_MIN_COUNT = 10\n",
        "\n",
        "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
        "                                            window=W2V_WINDOW, \n",
        "                                            min_count=W2V_MIN_COUNT, \n",
        "                                            workers=2)\n",
        "documents = [_text.split() for _text in msg_train]\n",
        "w2v_model.build_vocab(documents)"
      ],
      "metadata": {
        "id": "_3bP0FLPg6b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(\"Vocab size\", vocab_size)\n",
        "\n",
        "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3Q6zrSQl6zR",
        "outputId": "a84a051d-ca71-42e1-ca77-77c25b42f194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size 3150\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5973261, 10774304)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.most_similar(\"pray\")"
      ],
      "metadata": {
        "id": "9u0mBBKfjI02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Keras Tokenizer class**\n",
        "- Remove punctuation and split strings into lists of individual words\n",
        "- Convert the individual words into integers\n",
        "\n",
        "By default, this **removes all punctuation, lowercases words**, and then **converts words to sequences of integers**. A Tokenizer is first fit on a list of strings and then converts this list into a list of lists of integers."
      ],
      "metadata": {
        "id": "b1b2gcquaLNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "### Create a Tokenizer object\n",
        "tokenizer = Tokenizer(\n",
        "    ### max number of words to keep\n",
        "    # num_words = None,    \n",
        "\n",
        "    ### String of character to be removed, note that '!?\",.' are kept here\n",
        "    # filters = '#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',   \n",
        "\n",
        "    ##3 Whether to convert the texts to lowercase\n",
        "    lower = False, \n",
        "    \n",
        "    ### Separator for word splitting.\n",
        "    # split = ' '\n",
        "    )\n",
        "\n",
        "### Train the tokenizer to the texts\n",
        "tokenizer.fit_on_texts(msg_train)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Total words\", vocab_size)\n",
        "\n",
        "### Convert lists of srtrings into list of lists of integer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "SEQUENCE_LENGTH = 300\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(msg_train), maxlen=SEQUENCE_LENGTH)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(msg_test), maxlen=SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "id": "_quAMKqOatFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"msg_train\", x_train.shape)\n",
        "y_train = label_train.ravel().reshape(-1,1)\n",
        "print(\"label_train\", y_train.shape)\n",
        "print()\n",
        "print(\"msg_test\",x_test.shape)\n",
        "y_test = label_test.ravel().reshape(-1,1)\n",
        "print(\"label_test\", y_test.shape)"
      ],
      "metadata": {
        "id": "vM1j-mnNwgWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Embedding layer**\n",
        "\n",
        "Keras offers an ***Embedding layer*** that can be used for neural networks on text data.\n",
        "\n",
        "It requires that the input data be ***integer encoded***, so that each word is represented by a unique integer. This data preparation step can be performed using the Tokenizer API also provided with Keras.\n",
        "\n",
        "The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset.\n",
        "\n",
        "It is a flexible layer that can be used in a variety of ways, such as:\n",
        "\n",
        " - It can be used alone to learn a word embedding that can be saved and used in another model later.\n",
        " - It can be used as part of a deep learning model where the embedding is learned along with the model itself.\n",
        " - It can be used to load a pre-trained word embedding model, a type of transfer learning"
      ],
      "metadata": {
        "id": "w0GkNbOPYy5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size, W2V_SIZE"
      ],
      "metadata": {
        "id": "6IfCeNze1uHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94ed61e-b9ed-4cc0-b535-038f0a311e3e"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39739, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
        "from tensorflow.keras import callbacks\n",
        "import time\n",
        "import numpy as np\n",
        "def LSTM_model(msg_train, msg_test, label_train, label_test):\n",
        "  start_time = time.time()\n",
        "  model = Sequential()\n",
        "\n",
        "  # Embedding layer\n",
        "  embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
        "  for word, i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "      embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "  model.add(\n",
        "      Embedding(input_dim=vocab_size,\n",
        "                input_length = SEQUENCE_LENGTH,\n",
        "                output_dim=W2V_SIZE,\n",
        "                weights=[embedding_matrix],\n",
        "                trainable=False,\n",
        "                mask_zero=True))\n",
        "\n",
        "  # Masking layer for pre-trained embeddings\n",
        "  model.add(Masking(mask_value=0.0))\n",
        "\n",
        "  # Recurrent layer\n",
        "  model.add(LSTM(64, return_sequences=False, \n",
        "                dropout=0.1, recurrent_dropout=0.1))\n",
        "\n",
        "  # Fully connected layer\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "\n",
        "  # Dropout for regularization\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # Output layer\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  early_stopping = callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=5, restore_best_weights=True)\n",
        "  history_LSTM = model.fit(x_train, y_train, batch_size=8, validation_data=(x_test,y_test),epochs=8,verbose=1, callbacks=[early_stopping])\n",
        "  loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "  # predict the label of the train dataset\n",
        "  predictions = model.predict(x_test)\n",
        "  end_time = time.time()\n",
        "  return acc, pd.DataFrame(history_LSTM.history), predictions, end_time - start_time\n",
        "LSTM_acc, LSTM_plot, LSTM_predictions, LSTM_elapse_time = LSTM_model(x_train ,y_train, x_test, y_test)\n",
        "LSTM_plot.plot()\n",
        "print(f\"The accuracy of LSTM model is {LSTM_acc*100:0.1f}%, with training time {np.floor(LSTM_elapse_time/60)} minutes and {LSTM_elapse_time%60:0.0f} seconds.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "5zDAt8RqYtzs",
        "outputId": "b9d42e31-fabc-44d5-f1c9-99702648d523"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "3197/3197 [==============================] - 1756s 537ms/step - loss: 0.1845 - accuracy: 0.9377 - val_loss: 0.1623 - val_accuracy: 0.9454\n",
            "Epoch 2/8\n",
            "3197/3197 [==============================] - 1710s 535ms/step - loss: 0.1495 - accuracy: 0.9464 - val_loss: 0.1504 - val_accuracy: 0.9454\n",
            "Epoch 3/8\n",
            "2242/3197 [====================>.........] - ETA: 8:33 - loss: 0.1295 - accuracy: 0.9523"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-ca37c6b06175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_LSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mLSTM_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM_elapse_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mLSTM_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The accuracy of LSTM model is {LSTM_acc*100:0.1f}%, with training time {np.floor(LSTM_elapse_time/60)} minutes and {LSTM_elapse_time%60:0.0f} seconds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-138-ca37c6b06175>\u001b[0m in \u001b[0;36mLSTM_model\u001b[0;34m(msg_train, msg_test, label_train, label_test)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m   \u001b[0mhistory_LSTM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juQRefiz3tfk"
      },
      "source": [
        "### **Model Prediction & Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5gv8OnI3tfs"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "We will now evaluate our model to see how good it is in predicting the type of Tweet by comparing the predicted labels with the actual labels in our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9THpq8f3tfs"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiSvtKFoE4Ax"
      },
      "source": [
        "#### **Classification Report**\n",
        "We use different statistical evaluation methods to evaluate our model. You can read more about these methods [here](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd50ce4f-f636-420e-af81-60b7998c8105",
        "id": "sH9fOcui3tft"
      },
      "source": [
        "print(classification_report(LSTM_predictions,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97      6325\n",
            "           1       0.15      1.00      0.25        68\n",
            "\n",
            "    accuracy                           0.94      6393\n",
            "   macro avg       0.57      0.97      0.61      6393\n",
            "weighted avg       0.99      0.94      0.96      6393\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o36OpgkOGT6W"
      },
      "source": [
        "#### **Accuracy Score**\n",
        "Accuracy score is the percentage of correctly predicted labels. Note that there are chances to improve this accuracy by tuning parameters using GridSearchCV and other preprocessing techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976dadae-ab12-479b-9313-ee9dc5c0f718",
        "id": "8quWJfud3tft"
      },
      "source": [
        "print(accuracy_score(LSTM_predictions,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9374315657750665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p5psKJf3tft"
      },
      "source": [
        "#### **Confusion Matrix**\n",
        "The following confusion matrix can be read as:\n",
        "* Tweets with Positive Sentiment predicted correctly: 5954\n",
        "* Tweets with Positive Sentiment predicted incorrectly: 365\n",
        "* Tweets with Negative Sentiment predicted incorrectly: 2\n",
        "* Tweets with Negative Sentiment predicted correctly: 72"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6cb71e-b698-4b0f-9c5a-832c44623369",
        "id": "G9qfbGBk3tft"
      },
      "source": [
        "print(confusion_matrix(LSTM_predictions,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5925  400]\n",
            " [   0   68]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}